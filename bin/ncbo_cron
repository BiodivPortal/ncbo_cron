#!/usr/bin/env ruby

# Exit cleanly from an early interrupt
Signal.trap("INT") { exit 1 }

# Setup the bundled gems in our environment
require 'bundler/setup'
# redis store for looking up queued jobs
require 'redis'

# Used for getting jobs from the queue and processing them
require_relative '../lib/ncbo_cron'
config_exists = File.exist?(File.expand_path('../../config/config.rb', __FILE__))
abort("Please create a config/config.rb file using the config/config.rb.sample as a template") unless config_exists
require_relative '../config/config'

require 'optparse'
options = NcboCron.settings.to_h
opt_parser = OptionParser.new do |opts|
  # Set a banner, displayed at the top of the help screen.
  opts.banner = "Usage: ncbo_cron [options]"

  # Options from Dante gem, see
  # https://github.com/nesquena/dante/blob/master/lib/dante/runner.rb#L168-L214
  opts.on("-d", "--daemon", "Daemonize mode") do |v|
    options[:daemonize] = true
  end
  opts.on("-k", "--kill [PORT]", String, "Kill specified running daemons - leave blank to kill all.") do |v|
    options[:kill] = v
  end
  opts.on("-p", "--port PORT", Integer, "Specify port", "(default: #{options[:port]})") do |v|
    options[:port] = v
  end
  opts.on("-P", "--pid FILE", String, "save PID in FILE when using -d option.", "(default: #{options[:pid_path]})") do |v|
    options[:pid_path] = File.expand_path(v)
  end
  opts.on("-l", "--log FILE", String, "Logfile for output", "(default: #{options[:log_path]})") do |v|
    options[:log_path] = v
  end
  opts.on("-u", "--user USER", String, "User to run as") do |user|
    options[:user] = user
  end
  opts.on("-G", "--group GROUP", String, "Group to run as") do |group|
    options[:group] = group
  end

  # NCBO Cron options (may override options above, see validation below)
  opts.on("--console", "REPL for working with scheduler") do |v|
    options[:console] = true
  end
  opts.on("--view-queue", "view queued jobs") do |v|
    options[:view_queue] = true
  end
  opts.on("--add-submission ID", String, "submission id to add to the queue") do |v|
    options[:queue_submission] = v
  end
  opts.on("--redis-host HOST", String, "redis host (for shared locking)", "(default: #{options[:redis_host]})") do |host|
    options[:redis_host] = host
  end
  opts.on("--redis-port PORT", Integer, "redis port (for shared locking)", "(default: #{options[:redis_port]})") do |port|
    options[:redis_port] = port
  end
  opts.on("--log-level LEVEL", String, "set the log level (debug, info, error)", "(default: info)") do |c|
    options[:log_level] = c.to_sym
  end
  opts.on("--minutes MIN", Integer, "minutes between process queue checks (override seconds)") do |m|
    options[:minutes_between] = m
  end
  opts.on("--seconds SEC", Integer, "seconds between process queue checks") do |s|
    options[:seconds_between] = s
  end
  opts.on("--disable-annotator-dictionary", "disable annotator cache and dictionary rebuild") do |v|
    options[:enable_annotator_dictionary_rebuild] = false
  end
  opts.on("--disable-processing", "disable ontology processing") do |v|
    options[:enable_processing] = false
  end
  opts.on("--disable-pull", "disable ontology pull") do |v|
    options[:enable_pull] = false
  end
  opts.on("--disable-flush", "disable flush archive class graphs") do |v|
    options[:enable_flush] = false
  end
  opts.on("--disable-warmq", "disable query warmer") do |v|
    options[:enable_warmq] = false
  end
  opts.on("--enable-umls", "enable UMLS auto-pull") do |v|
    options[:enable_pull_umls] = true
  end
  opts.on("--pull-umls-url URL", "set UMLS pull location") do |v|
    options[:pull_umls_url] = v
  end
  opts.on("--pull-cron SCHED", String, "cron schedule for ontology pull") do |c|
    options[:cron_schedule] = c
  end
  opts.on("--annotator-dictionary-cron SCHED", String, "cron schedule for annotator cache and dictionary rebuild") do |c|
    options[:annotator_dictionary_rebuild_schedule] = c
  end
  opts.on("--flush-old-graphs SCHED", String, "cron schedule to delete class graphs of archive submissions") do |c|
    options[:cron_flush] = c
  end
  opts.on("--warm-long-queries SCHED", String, "cron schedule to warmup long time running queries") do |c|
    options[:cron_warmq] = c
  end
  # Display the help screen, all programs are assumed to have this option.
  opts.on_tail('--help', 'Display this screen' ) do
    puts opts
    exit
  end
end
# Parse the command-line. The 'parse' method simply parses ARGV, while the 'parse!' method parses ARGV and removes
# any options found there, as well as any parameters for the options.
opt_parser.parse!

# Verify options: daemon mode takes a back seat to other options.
if options[:view_queue] || options[:queue_submission] || options[:console] || options.include?(:kill)
  options[:daemonize] = false
  # The Dante runner will automatically redirect logs on runner.execute, if this option is set.
  options.delete(:log_path) # remove this here for more control over logging
end
if options[:daemonize] || options.include?(:kill)
  options[:console] = false
  options[:view_queue] = false
  options[:queue_submission] = false
  puts "Log file: #{options[:log_path]}" if options[:daemonize]
end

# Update the NcboCron.settings with CLI options
options.each_pair {|k,v| NcboCron.settings[k] = v}


# Configure the process controller
require 'dante'
runner = Dante::Runner.new('ncbo_cron', options)
runner.description = "This will run a scheduled job for NCBO-related processing"
runner.execute do |opts|

  redis = Redis.new(host: opts[:redis_host], port: opts[:redis_port])
  puts "Running ncbo_cron with redis: #{redis.inspect}"

  # If we're viewing queued entries, show them and quit
  if opts[:view_queue]
    parser = NcboCron::Models::OntologySubmissionParser.new
    queued_items = parser.queued_items(redis).map {|a| {ontology: a[:key], actions: a[:actions]}}
    puts "\n"
    queued_items.empty? ? puts("Nothing queued") : pp(queued_items)
    exit
  end

  # Queue a provided submission, then exit
  if opts[:queue_submission]
    puts "\n\nQueueing submission: #{opts[:queue_submission]}"
    sub = LinkedData::Models::OntologySubmission.find(RDF::URI.new(opts[:queue_submission])).first
    abort("Error: Submission not found") unless sub
    parser = NcboCron::Models::OntologySubmissionParser.new
    parser.queue_submission(sub)
    exit
  end

  if opts[:console]
    require 'pry'; binding.pry(quiet: true)
    exit
  end

  # Redirect stdout, stderr
  # The log opts are not set until now, because the stdout/stderr should not be
  # redirected for the view_queue, queue_submission, or console; the runner will
  # automatically redirect to logs on runner.execute, if the opts are set.
  require 'logger'
  log_file = File.new(options[:log_path], "a")
  logger = Logger.new(log_file, shift_age = 'daily')
  $stderr = log_file
  $stdout = log_file
  log_levels = {
    fatal: Logger::FATAL,
    error: Logger::ERROR,
    warn:  Logger::WARN,
    info:  Logger::INFO,
    debug: Logger::DEBUG
  }
  logger.level = log_levels[options[:log_level]]
  options['logger'] = logger

  puts "Running ncbo_cron with options:"
  pp options

  if options[:enable_processing]
    parsing_thread = Thread.new do
      logger.debug "Setting up process queue check job"; logger.flush
      parse_options = options.dup
      parse_options.delete(:cron_schedule)
      parse_options[:job_name] = "ncbo_cron_parsing"
      NcboCron::Scheduler.scheduled_locking_job(parse_options) do
        logger.info "Starting ontology process queue check"; logger.flush
        parser = NcboCron::Models::OntologySubmissionParser.new
        parser.process_queue_submissions()
        logger.info "Finished ontology process queue check"; logger.flush
      end
    end
    at_exit do
      if parsing_thread
        parsing_thread.kill
        parsing_thread.join
      end
    end
  end

  if options[:enable_pull]
    pull_thread = Thread.new do
      logger.debug "Setting up pull cron job"; logger.flush
      pull_options = options.dup
      pull_options.delete(:minutes_between)
      pull_options.delete(:seconds_between)
      pull_options[:job_name] = "pull_thread"
      pull_options[:scheduler_type] = :cron
      NcboCron::Scheduler.scheduled_locking_job(pull_options) do
        filename = File.basename(options[:log_path]).sub(/\.\w{1,4}$/, "")
        pull_log_path = options[:log_path].split("/")[0..-2].push("#{filename}-pull.log").join("/")
        pull_logger = Logger.new(pull_log_path, 'daily')
        logger.info "Starting ncbo pull"; logger.flush
        logger.info "Logging pull details to #{pull_log_path}"; logger.flush
        puller = NcboCron::Models::OntologyPull.new
        pulled_onts = puller.do_remote_ontology_pull(logger: pull_logger,
         enable_pull_umls: options[:enable_pull_umls])
        logger.info "Finished ncbo pull"; logger.flush
        logger.info "Pull summary:\n#{pulled_onts.map {|o| o.id.to_s}}"
      end
    end
    at_exit do
      if pull_thread
        pull_thread.kill
        pull_thread.join
      end
    end
  end

  if options[:enable_annotator_dictionary_rebuild]
    annotator_dictionary_rebuild_thread = Thread.new do
      logger.debug "Setting up annotator cache and dictionary rebuild cron job"; logger.flush
      annotator_dictionary_rebuild_options = options.dup
      annotator_dictionary_rebuild_options[:job_name] = "annotator_dictionary_rebuild_thread"
      annotator_dictionary_rebuild_options[:scheduler_type] = :cron
      annotator_dictionary_rebuild_options[:cron_schedule] = annotator_dictionary_rebuild_options[:annotator_dictionary_rebuild_schedule]
      NcboCron::Scheduler.scheduled_locking_job(annotator_dictionary_rebuild_options) do
        logger.info "Starting annotator cache and dictionary rebuild"; logger.flush
        annotator = Annotator::Models::NcboAnnotator.new
        annotator.create_term_cache(ontologies_filter=nil, delete_cache=true)
        annotator.generate_dictionary_file()
        logger.info "Finished annotator cache and dictionary rebuild"; logger.flush
      end
    end
    at_exit do
      if annotator_dictionary_rebuild_thread
        annotator_dictionary_rebuild_thread.kill
        annotator_dictionary_rebuild_thread.join
      end
    end
  end

  if options[:enable_flush]
    flush_thread = Thread.new do
      flush_options = options.dup
      flush_options.delete(:minutes_between)
      flush_options.delete(:seconds_between)
      flush_options[:job_name] = "flush_thread"
      flush_options[:scheduler_type] = :cron
      flush_options[:cron_schedule] = flush_options[:cron_flush]
      logger.debug "Setting up the flush cron job with options #{flush_options[:cron_flush]}"; logger.flush
      NcboCron::Scheduler.scheduled_locking_job(flush_options) do
        logger.info "Starting ncbo flush"; logger.flush
        filename = File.basename(options[:log_path]).sub(/\.\w{1,4}$/, "")
        flush_log_path = options[:log_path].split("/")[0..-2].push("#{filename}-flush.log").join("/")
        flush_logger = Logger.new(flush_log_path, "a")
        logger.info "Logging flush details to #{flush_log_path}"; logger.flush
        t0 = Time.now
        parser = NcboCron::Models::OntologySubmissionParser.new
        flush_onts = parser.process_flush_classes(flush_logger)
        logger.info "Flushed #{flush_onts.length} submissions in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished flush"; logger.flush
      end
    end
    at_exit do
      if flush_thread
        flush_thread.kill
        flush_thread.join
      end
    end
  end

  if options[:enable_warmq]
    warmq_thread = Thread.new do
      warmq_options = options.dup
      warmq_options.delete(:minutes_between)
      warmq_options.delete(:seconds_between)
      warmq_options[:job_name] = "warmq_thread"
      warmq_options[:scheduler_type] = :cron
      warmq_options[:cron_schedule] = warmq_options[:cron_warmq]
      logger.debug "Setting up warm up queries #{warmq_options[:cron_warmq]}"; logger.flush
      NcboCron::Scheduler.scheduled_locking_job(warmq_options) do
        logger.info "Starting ncbo warmq"; logger.flush
        filename = File.basename(options[:log_path]).sub(/\.\w{1,4}$/, "")
        warmq_log_path = options[:log_path].split("/")[0..-2].push("#{filename}-warmq.log").join("/")
        warmq_logger = Logger.new(warmq_log_path, "a")
        logger.info "Logging warmq details to #{warmq_log_path}"; logger.flush
        t0 = Time.now
        
        # TODO-DLW: why is this parser here?
        parser = NcboCron::Models::OntologySubmissionParser.new

        NcboCron::Models::QueryWarmer.new(warmq_logger).run
        logger.info "Warm queries job run in #{Time.now - t0} sec."; logger.flush
        logger.info "Finished warmq"; logger.flush
      end
    end
    at_exit do
      if warmq_thread
        warmq_thread.kill
        warmq_thread.join
      end
    end
  end

  parsing_thread.join if parsing_thread
  pull_thread.join if pull_thread
  flush_thread.join if flush_thread
  warmq_thread.join if warmq_thread
  annotator_dictionary_rebuild_thread.join if annotator_dictionary_rebuild_thread
end
